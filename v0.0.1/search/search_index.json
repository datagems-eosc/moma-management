{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"DataGEMS MoMa Management Api","text":"<p>This is the documentation site for the DataGEMS MoMa Management Api. The service is part of the wider DataGEMS platform. This is part of the overall platform documentation.</p> <p>The platform MoMa Management Api service acts as the ... for DataGEMS user interface and any other integrating clients that want to utilize the DataGEMS offerings.</p> <p>You can use the menu options on the left to navigate through the available documentation. You may be interested to jump directly to an Architecture Overview, see the available Onboarding Material, read about some Api Constructs, investigate how to interpret Status &amp; Error Codes or jump straight in to the OpenAPI Reference. You can find here the service code repository.</p> <p>For any questions, you can consult the FAQ, check if there is a relevant issue answering your question or contact the DataGEMS Help Desk.</p>"},{"location":"api-overview/","title":"Api Overview","text":"<p>TODO: Provide information</p>"},{"location":"architecture/","title":"Service Architecture","text":"<p>TODO: Provide information</p>"},{"location":"automations/","title":"Automations","text":"<p>A number of automations are available to facilitate the development, quality assurance, security, deployment, maintenance and onboarding of the service. Here we describe some that are directly, publicly available.</p>"},{"location":"automations/#dockerfile","title":"Dockerfile","text":"<p>The main delivery package for the service is a docker image. The Dockerfile bundled under the Http Api project for the service builds the Docker image.</p>"},{"location":"automations/#docker-image-publishing","title":"Docker image publishing","text":"<p>A GitHub Action workflow is available to build and publish the generated docker image for the service. The action is triggered when a new tag is created in the repository with a pattern of v*. This way, all the images produced are always named and can be traced back to the codebase snapshot that generated them.</p> <p>The generated docker image is pushed to the GitHub organization Packages using the name of the service repo and the version tag that triggered the execution.</p>"},{"location":"automations/#vulnerability-scanning","title":"Vulnerability Scanning","text":"<p>A GitHub Action workflow is available to scan for vulnerabilities any docker image that was created for the service. The action is triggered manually and expects as input the version tag that was used to generate the respective docker image that must be scanned.</p> <p>Vulnerability scanning is performed using Trivy. The results are generated in SARIF format and are made available in the GitHub Code Scanning tool that is configured for the service.</p> <p>Trivy is utilized to scan both the configuration that triggers the Docker image generation (ie the Dockerfile) as well as the generated image. The scanning performed on the generated image includes both OS vulnerabilities as well as installed libraries.</p>"},{"location":"automations/#static-code-analysis","title":"Static Code Analysis","text":"<p>A GitHub Action workflow is available to analyze the code using static code analysis offered through GitHub's CodeQL. The action is triggered manually and can be executed against the HEAD of the repository.</p> <p>The scan is configured to evaluate rules on security, quality and maintenability of the codebase. The results generated are made available in the GitHub Code Scanning tool that is configured for the service.</p>"},{"location":"automations/#code-metrics","title":"Code Metrics","text":"<p>A GitHub Action workflow is available to generate code metrics using ASP.NET Core msbuild targets. The action is triggered manually and can be executed against the HEAD of the repository.</p> <p>The generated metrics includes useful insight on metrics such as: * Maintenability index * Cyclomatic Complexity * Class Coupling * Depth of Inheritance * Lines of code</p> <p>The metrics are generated for the hierarchy of the code base, including Assembly, Namespace, Class, Method. This provides navigable insight. The results generated are in custom msbuild xml format and are available as action artefacts.</p>"},{"location":"automations/#documentation","title":"Documentation","text":"<p>A GitHub Action workflow is available to generate documentation available in the project in the format presented here. The action is triggered manually and can be executed against the head of the repository. The documentatino generated is versioned and the documentation version is expected as input to the workflow.</p> <p>The documentation is build using the mkdocs library and specifically using the Material for mkdocs plugin. A number of additional tools are ustilized, such as mike to support versioning, neoteroi.mkdocsoad to support OpenAPI specification rendering, and others.</p> <p>The documentation is generated and tagged with the provided version. It is uploaded to a dedicated documentation branch that is configured to be used as the base branch over which the repository GitHub Page presents its contents.</p>"},{"location":"automations/#testing","title":"Testing","text":"<p>A GitHub Action workflow is available to perform API smoke testing any configured installation of the service. The action is triggered manually and expects as input the version tag that contain the version of the tests that are compatible with the version of the deployed installation under test.</p> <p>Smoke testing of the APIs is perfomed using a Postman collection of requests. Configuration that needs to be passed in a protected way is maintained as GitHub Secrets. The request collection is axecuted using the Newman CLI. The output of the test run presents a summary of the requests performed and any errors that may have been observed.</p>"},{"location":"configuration/","title":"Configuration","text":"<p>This service is built using the ASP.NET Core framework, a cross-platform framework for building cloud-based web applications and APIs. ASP.NET Core offers a flexible configuration system that enables developers to manage application settings from a variety of sources, such as JSON files (like appsettings.json), environment variables, command-line arguments, secrets managers, and more. These configuration sources are automatically combined into a single, hierarchical configuration object that the application can use throughout its lifecycle.</p> <p>One of the key characteristics of ASP.NET Core\u2019s configuration system is its built-in support for environment-specific configurations. Developers can create environment-specific files like appsettings.Development.json, appsettings.Staging.json, or appsettings.Production.json, which override settings from the base configuration file. Additionally, environment variables or command-line arguments can further override any configuration values at runtime. This layered approach makes it easy to manage settings for different deployment environments, enabling a clear separation of concerns and promoting safe and consistent deployment practices.</p>"},{"location":"configuration/#configuration-files","title":"Configuration files","text":"<p>In the service we have opted for an approach that splits configuration properties in different configuration files depending on the application behavior they affect.</p> <ul> <li>accounting.json: Controls how accounting information is generated</li> <li>cache.json: Controls which mechanisms will be used for caching</li> <li>conversation.json: Controls the behavior of the Conversation feature</li> <li>cors.json: Controls CORS policies</li> <li>db.json: Controls the database connection</li> <li>errors.json: Vocabulary of error codes</li> <li>formatting.json: Controls how formatting of common datatypes is performed</li> <li>forwarded-headers.json: Controls the discovery of forwarded HTTP headers</li> <li>health-check.json: Controls the health check behavior</li> <li>idp.claims.json: Controls the extraction of known JWT claims</li> <li>idp.client.json: Controls the access of the service to the configured OIDC identity provider</li> <li>localization.json: Controls the localization behavior</li> <li>log-tracking.json: Controls the log correlation and log enrichment behavior</li> <li>logging.json: Controls the logging configuration</li> <li>open-api.json: Controls the OpenAPI specification generation</li> <li>permissions.json: Controls the authorization grants</li> <li>service-airflow.json: Controls the integation with the underpinning Airflow service</li> <li>service-cross-dataset-discovery.json: Controlls the integration with the underpinning Cross Dataset Discovery service</li> <li>service-data-management.json: Controlls the integration with the underpinning Data Management service</li> <li>service-in-data-exploration.json:  Controlls the integration with the underpinning In Data Exploration service</li> <li>user-collection.json: Controls the behavior of the Conversation feature</li> <li>vocabulary.json: Vocabularies used for model management</li> </ul>"},{"location":"configuration/#environment-overrides","title":"Environment Overrides","text":"<p>To facilitate configuring the service for different environments and allow reuse of overriding values, the service has a configuration substitution enabled tha tallows defining overriding keys to be used in various configuration values.</p> <p>For example, in idp.client.json the Idp:Client:Authority configuration option value is set to \"%{IdpAuthority}%\". If at another configuration file we define a property with a key of \"IdpAuthority\", the value of that property will substitute the value of the Idp:Client:Authority key.</p> <p>The practice employed is to define an env.[Environment].json file (eg env.Development.json) file where we place the various keys that need to be substituted. This way, and from a single location, we control the environment specific values.</p> <p>Additonally, configuration overrides can be applied through environment variables. Only variables starting with the prefix DG_GW_ are considered by the service configuration stack.</p> <p>For the ASP.NET environment to be properly bootstrapped, there are two envrionment variables that must be set explicitly:</p> <ul> <li>ASPNETCORE_ENVIRONMENT: This must define the envrionment in which the service runs. This value will control the \"Environment\" value in any xxx.[Environment].json configuration file that must be loaded</li> <li>ASPNETCORE_URLS: Indicates the IP addresses or host addresses with ports and protocols that the server should listen on for requests</li> </ul>"},{"location":"configuration/#secrets","title":"Secrets","text":"<p>Some of the configuration values contain sensitive data and should be treated differently. These may include secrets, connection strings, etc. It is suggested that, depending on the available infrastructure and tooling, the handling of these values is done separately from other configuration values.</p>"},{"location":"datastore/","title":"Data Stores","text":"<p>The service functions primarily as a gateway between the user interface, or other external integration points, and the core DataGEMS services. While it does not serve as the main repository for datasets or models related to most user requests, it plays a critical role in facilitating access to core platform features. As such, it must manage certain operational data necessary to support its responsibilities and ensure smooth interaction with the broader system.</p>"},{"location":"datastore/#relational-database","title":"Relational Database","text":"<p>The primary data store for the service is a PostgreSQL hosted relational database.</p> <p>The schema of the relational database can be found in the service repository under the db folder.</p>"},{"location":"datastore/#change-scripts","title":"Change scripts","text":"<p>The evolution of the database is managed through ordered database change scripts. The scripts incrimentaly update the database schema to target the desired version. The change scripts are numbered and versioned in the service repository under the db folder.</p> <p>Intermediate \"XX.XX.XXX-Seed.Scema.sql\" scripts can be used to initialize the database in the sepecific version so that previous change scripts do not need to be applied.</p>"},{"location":"deployment/","title":"Deployment","text":"<p>The service is part of the DataGEMS platform offered through an existing deployment, following the DataGEMS release and deployment procedures over a managed infrasrtucture. The purpose of this section is not to detail the deployment processes put in place by the DataGEMS team.</p>"},{"location":"deployment/#docker","title":"Docker","text":"<p>The service is offered as a Docker image through the DataGEMS GitHub Organization Packages. This process is described in the relevant Automations section.</p>"},{"location":"deployment/#configuration","title":"Configuration","text":"<p>In order for the service to operate properly, the needed configuration values must be set to match the environment that it must operate in. The needed configuration is described in the relevant Configuration section.</p>"},{"location":"deployment/#dependencies","title":"Dependencies","text":"<p>For the service to be able to operate, its underpinning services and dependnecies must be available and accessible. The Architecture section describes the ecosystem in which the service needs to operate.</p>"},{"location":"error-codes/","title":"Status &amp; Error Codes","text":"<p>The HTTP Api exposed by the service exposes restful endpoints to offer its functionality. These endpoints are documented using the OpenAPI specification and available for integrators to consult in the respective API section.</p> <p>In this section, we describe further the HTTP Status Codes that the service may expose and possible Error Codes that can be expected.</p>"},{"location":"error-codes/#status-codes","title":"Status Codes","text":"<p>Commonly used HTTP Response codes are in the service. It makes proper usage of these HTTP Status Codes and tries not to abuse their semantics. The following subset is used and documented in the respective OpenAPI document:</p> <ul> <li>200 OK - request has succeeded</li> <li>400 Bad Request - request not processed due to a request/client error</li> <li>401 Unauthorized - request was not successful because it lacks valid authentication credentials</li> <li>403 Forbidden - understood the request but refused to process it. Authenticating or re-authenticating makes no difference. The request failure is tied to application logic, such as insufficient permissions to a resource or action</li> <li>404 Not Found - cannot find the requested resource</li> <li>424 Failed Dependency - method could not be performed on the resource because the requested action depended on another action, and that action failed</li> <li>500 Internal Server Error - encountered an unexpected condition that prevented the service from fulfilling the request</li> </ul>"},{"location":"error-codes/#error-codes","title":"Error Codes","text":"<p>For unsucessful requests (other than 200 OK), there may be additional information that can and are provided to the caller. They should be considered as refinements of the error category that is defined through the respective HTTP Status Code of the response. The additional information is provided in both a system friendly error code as well as a user friendly message.</p> <p>The service exposes the following error codes, depending on the HTTP Status Code that will be returned:</p> <ul> <li>System Error<ul> <li>Code: 100</li> <li>Error: an unexpected system error occured</li> </ul> </li> <li>Forbidden<ul> <li>Code\": 101</li> <li>Error: insufficient rights</li> </ul> </li> <li>Model Validation<ul> <li>Code: 102</li> <li>Error: validation error structured description</li> </ul> </li> <li>Unsupported Action<ul> <li>Code: 103</li> <li>Error: request for unsupported action</li> </ul> </li> <li>Underpinning Service<ul> <li>Code: 104</li> <li>Error: error communicating with underpinning service</li> </ul> </li> <li>Token Exchange<ul> <li>Code: 105</li> <li>Error: error exchanging tokens for underpinning service</li> </ul> </li> <li>User Sync<ul> <li>Code: 106</li> <li>Error: authorized user out of sync with internal registry</li> </ul> </li> <li>Concurrent Update Conflict<ul> <li>Code: 107</li> <li>Error: there is an etag conflict for the item modifed with Id = X of Type = Y. please reload to get the latest changes</li> </ul> </li> <li>Immutable Item<ul> <li>Code: 108</li> <li>Error: you are trying to modify an immutable item or property</li> </ul> </li> </ul>"},{"location":"error-codes/#bad-requests","title":"Bad requests","text":"<p>Specifically for the case of responses with status code 400 (Bad Request), with an error code 102 (Model Validation), the response message may include additional structured information on the kind of error that was identified.</p> <p>For example, if the caller is requesting a paged list of results without providing the ordering to be used and the service does not support default ordering, the response will be a 400 Bad Request with a payload as bellow</p> <pre><code>{\n    \"code\": 102,\n    \"error\": \"Validation Error\",\n    \"message\": [\n        {\n            \"Key\": \"Page\",\n            \"Value\": [\n                \"paging not supported without ordering\"\n            ]\n        }\n    ]\n}\n</code></pre> <p>The \"Key\" binds directly to the request property that was problematic.</p> <p>In case the request had an array of objects and one of the properties within the array objects was failty, the key would indicate the specific failty object and property. So, if we try to update a User Collection providing also the links to the Datasets that is should contain but we do not provide the dataset id for the 4th item in the list (index 3), the response will look like the following:</p> <pre><code>{\n    \"code\": 102,\n    \"error\": \"Validation Error\",\n    \"message\": [\n        {\n            \"Key\": \"UserDatasetCollections[3].DatasetId\",\n            \"Value\": [\n                \"DatasetId is required\"\n            ]\n        }\n    ]\n}\n</code></pre>"},{"location":"error-codes/#failed-dependency","title":"Failed Dependency","text":"<p>When this status code is used, the service, in the process of serving the request, calls other services. One of its underpinning services did not operate as expected to complete the processing of the request sucessfuly. The response status code would be a 424 Failed Dependency with the needed code and error message. But it can also contain additional information about the underpinning service reported error. This way, the response will contain all the information that the service can provide, without needed to redefine all the possible error conditions of its underpinning services. Additionally, this gives the possibility to track the error stack across multiple services if needed. An example of such a case might be:</p> <pre><code>{\n    \"code\": 104,\n    \"error\": \"error communicating with underpinning service\",\n    \"message\": {\n        \"statusCode\": 500,\n        \"source\": \"the service name\",\n        \"correlationId\": \"log correlation identifier\"\n    }\n}\n</code></pre> <p>The intend of propagating additional payload from the underpining service response in the payload is to assist in identifying issues that can be managed in the context of the request, not to provide general troubleshooting capabilities. For the later, the correlationId is included so that if reported additonal information can be retrieved from the logsm as covered in the relevant Logging section. But in case the underpinning service response code is a 400 Bad Request, that means that this is something that the caller will need to be notified about as it may be something that can be fixed in the context of the request. So, in such cases, another example could be:</p> <pre><code>{\n    \"code\": 104,\n    \"error\": \"error communicating with underpinning service\",\n    \"message\": {\n        \"statusCode\": 400,\n        \"source\": \"the service name\",\n        \"correlationId\": \"log correlation identifier\",\n        \"payload\": {\n          \"code\": 102,\n          \"error\": \"Validation Error\",\n          \"message\": [\n              {\n                  \"Key\": \"Page\",\n                  \"Value\": [\n                      \"paging not supported without ordering\"\n                  ]\n              }\n          ]\n        }\n    }\n}\n</code></pre>"},{"location":"faq/","title":"Frequently Asked Questions (FAQ)","text":""},{"location":"faq/#is-datagems-really-that-awsome","title":"Is DataGEMS really that awsome?","text":"<p>Yes, it is.</p>"},{"location":"license/","title":"License","text":"<pre><code>                  EUROPEAN UNION PUBLIC LICENCE v. 1.2\n                  EUPL \u00a9 the European Union 2007, 2016\n</code></pre> <p>This European Union Public Licence (the \u2018EUPL\u2019) applies to the Work (as defined below) which is provided under the terms of this Licence. Any use of the Work, other than as authorised under this Licence is prohibited (to the extent such use is covered by a right of the copyright holder of the Work).</p> <p>The Work is provided under the terms of this Licence when the Licensor (as defined below) has placed the following notice immediately following the copyright notice for the Work:</p> <pre><code>    Licensed under the EUPL\n</code></pre> <p>or has expressed by any other means his willingness to license under the EUPL.</p> <ol> <li>Definitions</li> </ol> <p>In this Licence, the following terms have the following meaning:</p> <ul> <li> <p>\u2018The Licence\u2019: this Licence.</p> </li> <li> <p>\u2018The Original Work\u2019: the work or software distributed or communicated by the   Licensor under this Licence, available as Source Code and also as Executable   Code as the case may be.</p> </li> <li> <p>\u2018Derivative Works\u2019: the works or software that could be created by the   Licensee, based upon the Original Work or modifications thereof. This Licence   does not define the extent of modification or dependence on the Original Work   required in order to classify a work as a Derivative Work; this extent is   determined by copyright law applicable in the country mentioned in Article 15.</p> </li> <li> <p>\u2018The Work\u2019: the Original Work or its Derivative Works.</p> </li> <li> <p>\u2018The Source Code\u2019: the human-readable form of the Work which is the most   convenient for people to study and modify.</p> </li> <li> <p>\u2018The Executable Code\u2019: any code which has generally been compiled and which is   meant to be interpreted by a computer as a program.</p> </li> <li> <p>\u2018The Licensor\u2019: the natural or legal person that distributes or communicates   the Work under the Licence.</p> </li> <li> <p>\u2018Contributor(s)\u2019: any natural or legal person who modifies the Work under the   Licence, or otherwise contributes to the creation of a Derivative Work.</p> </li> <li> <p>\u2018The Licensee\u2019 or \u2018You\u2019: any natural or legal person who makes any usage of   the Work under the terms of the Licence.</p> </li> <li> <p>\u2018Distribution\u2019 or \u2018Communication\u2019: any act of selling, giving, lending,   renting, distributing, communicating, transmitting, or otherwise making   available, online or offline, copies of the Work or providing access to its   essential functionalities at the disposal of any other natural or legal   person.</p> </li> <li> <p>Scope of the rights granted by the Licence</p> </li> </ul> <p>The Licensor hereby grants You a worldwide, royalty-free, non-exclusive, sublicensable licence to do the following, for the duration of copyright vested in the Original Work:</p> <ul> <li>use the Work in any circumstance and for all usage,</li> <li>reproduce the Work,</li> <li>modify the Work, and make Derivative Works based upon the Work,</li> <li>communicate to the public, including the right to make available or display   the Work or copies thereof to the public and perform publicly, as the case may   be, the Work,</li> <li>distribute the Work or copies thereof,</li> <li>lend and rent the Work or copies thereof,</li> <li>sublicense rights in the Work or copies thereof.</li> </ul> <p>Those rights can be exercised on any media, supports and formats, whether now known or later invented, as far as the applicable law permits so.</p> <p>In the countries where moral rights apply, the Licensor waives his right to exercise his moral right to the extent allowed by law in order to make effective the licence of the economic rights here above listed.</p> <p>The Licensor grants to the Licensee royalty-free, non-exclusive usage rights to any patents held by the Licensor, to the extent necessary to make use of the rights granted on the Work under this Licence.</p> <ol> <li>Communication of the Source Code</li> </ol> <p>The Licensor may provide the Work either in its Source Code form, or as Executable Code. If the Work is provided as Executable Code, the Licensor provides in addition a machine-readable copy of the Source Code of the Work along with each copy of the Work that the Licensor distributes or indicates, in a notice following the copyright notice attached to the Work, a repository where the Source Code is easily and freely accessible for as long as the Licensor continues to distribute or communicate the Work.</p> <ol> <li>Limitations on copyright</li> </ol> <p>Nothing in this Licence is intended to deprive the Licensee of the benefits from any exception or limitation to the exclusive rights of the rights owners in the Work, of the exhaustion of those rights or of other applicable limitations thereto.</p> <ol> <li>Obligations of the Licensee</li> </ol> <p>The grant of the rights mentioned above is subject to some restrictions and obligations imposed on the Licensee. Those obligations are the following:</p> <p>Attribution right: The Licensee shall keep intact all copyright, patent or trademarks notices and all notices that refer to the Licence and to the disclaimer of warranties. The Licensee must include a copy of such notices and a copy of the Licence with every copy of the Work he/she distributes or communicates. The Licensee must cause any Derivative Work to carry prominent notices stating that the Work has been modified and the date of modification.</p> <p>Copyleft clause: If the Licensee distributes or communicates copies of the Original Works or Derivative Works, this Distribution or Communication will be done under the terms of this Licence or of a later version of this Licence unless the Original Work is expressly distributed only under this version of the Licence \u2014 for example by communicating \u2018EUPL v. 1.2 only\u2019. The Licensee (becoming Licensor) cannot offer or impose any additional terms or conditions on the Work or Derivative Work that alter or restrict the terms of the Licence.</p> <p>Compatibility clause: If the Licensee Distributes or Communicates Derivative Works or copies thereof based upon both the Work and another work licensed under a Compatible Licence, this Distribution or Communication can be done under the terms of this Compatible Licence. For the sake of this clause, \u2018Compatible Licence\u2019 refers to the licences listed in the appendix attached to this Licence. Should the Licensee's obligations under the Compatible Licence conflict with his/her obligations under this Licence, the obligations of the Compatible Licence shall prevail.</p> <p>Provision of Source Code: When distributing or communicating copies of the Work, the Licensee will provide a machine-readable copy of the Source Code or indicate a repository where this Source will be easily and freely available for as long as the Licensee continues to distribute or communicate the Work.</p> <p>Legal Protection: This Licence does not grant permission to use the trade names, trademarks, service marks, or names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the copyright notice.</p> <ol> <li>Chain of Authorship</li> </ol> <p>The original Licensor warrants that the copyright in the Original Work granted hereunder is owned by him/her or licensed to him/her and that he/she has the power and authority to grant the Licence.</p> <p>Each Contributor warrants that the copyright in the modifications he/she brings to the Work are owned by him/her or licensed to him/her and that he/she has the power and authority to grant the Licence.</p> <p>Each time You accept the Licence, the original Licensor and subsequent Contributors grant You a licence to their contributions to the Work, under the terms of this Licence.</p> <ol> <li>Disclaimer of Warranty</li> </ol> <p>The Work is a work in progress, which is continuously improved by numerous Contributors. It is not a finished work and may therefore contain defects or \u2018bugs\u2019 inherent to this type of development.</p> <p>For the above reason, the Work is provided under the Licence on an \u2018as is\u2019 basis and without warranties of any kind concerning the Work, including without limitation merchantability, fitness for a particular purpose, absence of defects or errors, accuracy, non-infringement of intellectual property rights other than copyright as stated in Article 6 of this Licence.</p> <p>This disclaimer of warranty is an essential part of the Licence and a condition for the grant of any rights to the Work.</p> <ol> <li>Disclaimer of Liability</li> </ol> <p>Except in the cases of wilful misconduct or damages directly caused to natural persons, the Licensor will in no event be liable for any direct or indirect, material or moral, damages of any kind, arising out of the Licence or of the use of the Work, including without limitation, damages for loss of goodwill, work stoppage, computer failure or malfunction, loss of data or any commercial damage, even if the Licensor has been advised of the possibility of such damage. However, the Licensor will be liable under statutory product liability laws as far such laws apply to the Work.</p> <ol> <li>Additional agreements</li> </ol> <p>While distributing the Work, You may choose to conclude an additional agreement, defining obligations or services consistent with this Licence. However, if accepting obligations, You may act only on your own behalf and on your sole responsibility, not on behalf of the original Licensor or any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against such Contributor by the fact You have accepted any warranty or additional liability.</p> <ol> <li>Acceptance of the Licence</li> </ol> <p>The provisions of this Licence can be accepted by clicking on an icon \u2018I agree\u2019 placed under the bottom of a window displaying the text of this Licence or by affirming consent in any other similar way, in accordance with the rules of applicable law. Clicking on that icon indicates your clear and irrevocable acceptance of this Licence and all of its terms and conditions.</p> <p>Similarly, you irrevocably accept this Licence and all of its terms and conditions by exercising any rights granted to You by Article 2 of this Licence, such as the use of the Work, the creation by You of a Derivative Work or the Distribution or Communication by You of the Work or copies thereof.</p> <ol> <li>Information to the public</li> </ol> <p>In case of any Distribution or Communication of the Work by means of electronic communication by You (for example, by offering to download the Work from a remote location) the distribution channel or media (for example, a website) must at least provide to the public the information requested by the applicable law regarding the Licensor, the Licence and the way it may be accessible, concluded, stored and reproduced by the Licensee.</p> <ol> <li>Termination of the Licence</li> </ol> <p>The Licence and the rights granted hereunder will terminate automatically upon any breach by the Licensee of the terms of the Licence.</p> <p>Such a termination will not terminate the licences of any person who has received the Work from the Licensee under the Licence, provided such persons remain in full compliance with the Licence.</p> <ol> <li>Miscellaneous</li> </ol> <p>Without prejudice of Article 9 above, the Licence represents the complete agreement between the Parties as to the Work.</p> <p>If any provision of the Licence is invalid or unenforceable under applicable law, this will not affect the validity or enforceability of the Licence as a whole. Such provision will be construed or reformed so as necessary to make it valid and enforceable.</p> <p>The European Commission may publish other linguistic versions or new versions of this Licence or updated versions of the Appendix, so far this is required and reasonable, without reducing the scope of the rights granted by the Licence. New versions of the Licence will be published with a unique version number.</p> <p>All linguistic versions of this Licence, approved by the European Commission, have identical value. Parties can take advantage of the linguistic version of their choice.</p> <ol> <li>Jurisdiction</li> </ol> <p>Without prejudice to specific agreement between parties,</p> <ul> <li> <p>any litigation resulting from the interpretation of this License, arising   between the European Union institutions, bodies, offices or agencies, as a   Licensor, and any Licensee, will be subject to the jurisdiction of the Court   of Justice of the European Union, as laid down in article 272 of the Treaty on   the Functioning of the European Union,</p> </li> <li> <p>any litigation arising between other parties and resulting from the   interpretation of this License, will be subject to the exclusive jurisdiction   of the competent court where the Licensor resides or conducts its primary   business.</p> </li> <li> <p>Applicable Law</p> </li> </ul> <p>Without prejudice to specific agreement between parties,</p> <ul> <li> <p>this Licence shall be governed by the law of the European Union Member State   where the Licensor has his seat, resides or has his registered office,</p> </li> <li> <p>this licence shall be governed by Belgian law if the Licensor has no seat,   residence or registered office inside a European Union Member State.</p> </li> </ul> <p>Appendix</p> <p>\u2018Compatible Licences\u2019 according to Article 5 EUPL are:</p> <ul> <li>GNU General Public License (GPL) v. 2, v. 3</li> <li>GNU Affero General Public License (AGPL) v. 3</li> <li>Open Software License (OSL) v. 2.1, v. 3.0</li> <li>Eclipse Public License (EPL) v. 1.0</li> <li>CeCILL v. 2.0, v. 2.1</li> <li>Mozilla Public Licence (MPL) v. 2</li> <li>GNU Lesser General Public Licence (LGPL) v. 2.1, v. 3</li> <li>Creative Commons Attribution-ShareAlike v. 3.0 Unported (CC BY-SA 3.0) for   works other than software</li> <li>European Union Public Licence (EUPL) v. 1.1, v. 1.2</li> <li>Qu\u00e9bec Free and Open-Source Licence \u2014 Reciprocity (LiLiQ-R) or Strong   Reciprocity (LiLiQ-R+).</li> </ul> <p>The European Commission may update this Appendix to later versions of the above licences without producing a new version of the EUPL, as long as they provide the rights granted in Article 2 of this Licence and protect the covered Source Code from exclusive appropriation.</p> <p>All other changes or additions to this Appendix require the production of a new EUPL version.</p>"},{"location":"logging/","title":"Logging","text":"<p>All DataGEMS services are producing logs in a structured way, usilizing common log formats. The logs are aggregated to the Logging Service where they can be queried and analyzed.</p>"},{"location":"logging/#log-format","title":"Log format","text":"<p>The service utilized serilog for structured logging. The respective Configuration section describes where this is configured.</p> <p>The log format utilized by is compact json providing structured presentation of the information presented. This is easily parsed and made available for further processing.</p>"},{"location":"logging/#correlation-identifier","title":"Correlation Identifier","text":"<p>A key property in enabling troubleshooting in the micro-service DataGEMS architecture is the Correlation Identifier.</p> <p>In order to serve a user request, a number of services invocations may be chained. It will be useful to be able to track the chain of the request across all involved services. To achive this, we utilize a shared Correlation Id that is generated early in the call stack and propagated across all subsequent invocations.</p> <p>At the begining of the request stack, we check if there is a correlation id provided for the request in the request headers typically under a header named x-tracking-correlation. If not, we generate one for the request and any downstream calls. We also add it in the logging configuration so that all subsequent log messages include this correlation id.</p> <p>At the time of invoking another service, we include the correlation id header, along with the correlation id value so that the next service in line will use the same identifier.</p> <p>The respective Configuration section describes where this behavior is configured.</p>"},{"location":"logging/#troubleshooting-logs","title":"Troubleshooting Logs","text":"<p>Troubleshooting logs are produced by the service throughout the execution of caller requests. The messages are separated by the log level:</p> <ul> <li>Trace</li> <li>Debug</li> <li>Information</li> <li>Warning</li> <li>Error</li> <li>Critical</li> </ul> <p>Log entries may contain the following information (where available):</p> <ul> <li>Timestamp in UTC (ISO8601)</li> <li>Correlation Identifier</li> <li>Subject Id</li> <li>Client Id</li> <li>Message text</li> <li>Log Level</li> <li>... additional properties</li> </ul> <p>An prettified example of a log entry is:</p> <pre><code>[\n    {\n        \"@t\": \"2025-08-08T11:13:14.8335054Z\",\n        \"@mt\": \"{\\\"msg\\\":\\\"building\\\",\\\"m\\\":{\\\"type\\\":\\\"Collection\\\",\\\"fields\\\":{\\\"Fields\\\":[\\\"id\\\",\\\"code\\\",\\\"name\\\",\\\"datasetcount\\\"]},\\\"dataCount\\\":5}}\",\n        \"@l\": \"Debug\",\n        \"@tr\": \"c3e3abe1e71da568c1dceb387b19a7ff\",\n        \"@sp\": \"5eee2c1f0d5309b2\",\n        \"SourceContext\": \"DataGEMS.Gateway.App.Model.Builder.CollectionBuilder\",\n        \"ActionId\": \"654d5a3b-9980-4684-a70a-4eedaada7b99\",\n        \"ActionName\": \"DataGEMS.Gateway.Api.Controllers.DatasetController.Query (DataGEMS.Gateway.Api)\",\n        \"RequestId\": \"0HNEMDADKBH0J:00000001\",\n        \"RequestPath\": \"/api/dataset/query\",\n        \"ConnectionId\": \"0HNEMDADKBH0J\",\n        \"ClientId\": null,\n        \"Username\": null,\n        \"UserId\": \"the subject id\",\n        \"DGCorrelationId\": \"the correlation id\",\n        \"MachineName\": \"the machine name\",\n        \"ProcessId\": 1,\n        \"ThreadId\": 19,\n        \"Application\": \"the application id\"\n    },\n    {\n        \"@t\": \"2025-08-08T11:13:14.8357014Z\",\n        \"@mt\": \"HTTP {RequestMethod} {RequestPath} responded {StatusCode} in {Elapsed:0.0000} ms\",\n        \"@r\": [\n            \"38.1723\"\n        ],\n        \"@tr\": \"03cb7b58744f0d0e3ffff2e05ce85ed5\",\n        \"@sp\": \"cfc6357aff7c7c7c\",\n        \"RequestMethod\": \"POST\",\n        \"RequestPath\": \"/api/dataset/query\",\n        \"StatusCode\": 200,\n        \"Elapsed\": 38.172305,\n        \"SourceContext\": \"Serilog.AspNetCore.RequestLoggingMiddleware\",\n        \"DGCorrelationId\": \"the correlation id\",\n        \"RequestId\": \"0HNEMDADKBH0H:00000001\",\n        \"ConnectionId\": \"0HNEMDADKBH0H\",\n        \"MachineName\": \"the machine name\",\n        \"ProcessId\": 1,\n        \"ThreadId\": 19,\n        \"Application\": \"the application id\"\n    }\n]\n</code></pre>"},{"location":"logging/#accounting-logs","title":"Accounting Logs","text":"<p>The service generates accounting entries that utilize the same logging mechanism but are differentiated by troubleshooting logs through the \"SourceContext\" property which is set to \"accounting\".</p> <p>These accounting log entries are harvested and processed by the Accounting Service</p> <p>A prettified example of an accounting log entry is: <pre><code>{\n    \"@t\": \"2025-08-08T11:13:14.8354027Z\",\n    \"@mt\": \"{\\\"m\\\":{\\\"timestamp\\\":\\\"2025-08-08T11:13:14.8353562Z\\\",\\\"serviceId\\\":\\\"the service id\\\",\\\"action\\\":\\\"Query\\\",\\\"resource\\\":\\\"Dataset\\\",\\\"userId\\\":\\\"the subject id\\\",\\\"value\\\":\\\"1\\\",\\\"measure\\\":\\\"Unit\\\",\\\"type\\\":\\\"+\\\"}}\",\n    \"@tr\": \"03cb7b58744f0d0e3ffff2e05ce85ed5\",\n    \"@sp\": \"cfc6357aff7c7c7c\",\n    \"SourceContext\": \"accounting\",\n    \"ActionId\": \"654d5a3b-9980-4684-a70a-4eedaada7b99\",\n    \"ActionName\": \"DataGEMS.Gateway.Api.Controllers.DatasetController.Query (DataGEMS.Gateway.Api)\",\n    \"RequestId\": \"0HNEMDADKBH0H:00000001\",\n    \"RequestPath\": \"/api/dataset/query\",\n    \"ConnectionId\": \"0HNEMDADKBH0H\",\n    \"ClientId\": null,\n    \"Username\": null,\n    \"UserId\": \"the subject id\",\n    \"DGCorrelationId\": \"the correlation id\",\n    \"MachineName\": \"the machine name\",\n    \"ProcessId\": 1,\n    \"ThreadId\": 19,\n    \"Application\": \"the application id\"\n}\n</code></pre></p> <p>The @mt property contains the information that is intended to be utilized by the accounting service to track this action: <pre><code>{\n    \"m\": {\n        \"timestamp\": \"2025-08-08T11:13:14.8353562Z\",\n        \"serviceId\": \"the service id\",\n        \"action\": \"Query\",\n        \"resource\": \"Dataset\",\n        \"userId\": \"the subject id\",\n        \"value\": \"1\",\n        \"measure\": \"Unit\",\n        \"type\": \"+\"\n    }\n}\n</code></pre></p>"},{"location":"maintenance/","title":"Maintenance","text":"<p>The service is part of the DataGEMS platform offered through an existing deployment, following the DataGEMS release and deployment procedures over a managed infrasrtucture along with the maintenance activities that are scheduled within the platform. The purpose of this section is not to detail the maintenance activities put in place by the DataGEMS team.</p>"},{"location":"maintenance/#healthchecks","title":"Healthchecks","text":"<p>The service OpenAPI Reference describes healthcheck endpoints that can be used to track the status of the service.</p> <p>The appropriate configuration file that controls the behavior of the healthcheck endpoints is described in the relevant Configuration section along with the response status codes for Healthy / Degrades / Unhealthy status and if the response will be verbose.</p> <p>An example of a Verbose response that returns 200 OK for healthy state is: <pre><code>{\n    \"status\": \"Healthy\",\n    \"duration\": \"00:00:00.0216780\",\n    \"results\": {\n        \"privateMemory\": {\n            \"status\": \"Healthy\",\n            \"description\": null,\n            \"duration\": \"00:00:00.0015544\",\n            \"tags\": null,\n            \"exception\": null,\n            \"data\": {}\n        },\n        \"processMemory\": {\n            \"status\": \"Healthy\",\n            \"description\": \"Allocated megabytes in memory: 408 mb\",\n            \"duration\": \"00:00:00.0000382\",\n            \"tags\": null,\n            \"exception\": null,\n            \"data\": {}\n        },\n        \"db\": {\n            \"status\": \"Healthy\",\n            \"description\": null,\n            \"duration\": \"00:00:00.0211601\",\n            \"tags\": null,\n            \"exception\": null,\n            \"data\": {}\n        }\n    }\n}\n</code></pre></p>"},{"location":"maintenance/#verions-updates","title":"Verions &amp; Updates","text":"<p>The service follows a semantic versioning scheme and structures versions as MAJOR.MINOR.PATCH:</p> <ul> <li>MAJOR (X.0.0): Breaking changes that are incompatible with previous versions.</li> <li>MINOR (X.Y.0): New features added in a backward-compatible way.</li> <li>PATCH (X.Y.Z): Bug fixes and security patches that do not affect compatibility.</li> </ul>"},{"location":"maintenance/#backups","title":"Backups","text":"<p>All state persisted by the service is maintained in the relational database as described in the respective datastores section.</p> <p>To keep backups of the state, the respective utilities must be scheduled to run in a consistent manner.</p>"},{"location":"maintenance/#troubleshooting","title":"Troubleshooting","text":"<p>Troubleshooting is primarily done through the logging mechanisms that are available and are described in the respective logging section.</p>"},{"location":"onboarding/","title":"Onboarding Material","text":"<p>This section contains some references and material that will assist users and integrators onboarding process.</p>"},{"location":"onboarding/#references","title":"References","text":"<p>The definite guide for integrators remains the service OpenAPI Reference.</p> <p>The codebase is available under EUROPEAN UNION PUBLIC LICENCE v. 1.2 (EUPL v1.2) in our GitHub code repository.</p> <p>To get a better understanding on features and approaches utilized throughout the HTTP Api interface, you can read about some Api Constructs.</p> <p>To know more about Api response codes and how to interpret them, you can take a look at the Status &amp; Error Codes.</p> <p>On aspect pertaining to security, you can read more at the Secruity section.</p> <p>For an overall view of the service, you can go through the Architecture.</p> <p>For any questions, you can consult the FAQ.</p> <p>If you are facing a problem, check if there is a relevant issue answering your question.</p> <p>You can always contact us through the DataGEMS Help Desk.</p>"},{"location":"onboarding/#examples","title":"Examples","text":"<p>You can find here a postman collection that describes some example calls of the Api. You will need to create an environment and define the following variables:</p> <ul> <li>userAccessToken: set here the access token retrieved from the DataGEMS AAI service</li> <li>baseUrl: set this to the api endpoint you want to use</li> </ul> <p>Depending on the access level of the user that was authenticated and whose access token you have placed in the userAccessToken variable, you will be able to utilize the respective endpoints.</p> <p>The postman collection can be found here: DataGEMS.dg-app-api.postman-collection.json.</p>"},{"location":"onboarding/#tutorials","title":"Tutorials","text":"<p>You can find useful material and onboarding guidelines in our social channels bellow, as well as our platform documentation.</p>"},{"location":"onboarding/#keep-in-touch","title":"Keep in touch","text":"<p>Make sure to follow the DataGEMS channels to get the latest news and references:</p> <ul> <li>GitHub</li> <li>Instagram</li> <li>X</li> <li>YoutTube</li> <li>LinkedIn</li> <li>Facebook</li> </ul>"},{"location":"openapi/","title":"OpenAPI","text":""},{"location":"openapi/#dataset-api-100","title":"Dataset API 1.0.0","text":"<p>API for data and model management</p>"},{"location":"openapi/#servers","title":"Servers","text":"Description URL /dmm /dmm"},{"location":"openapi/#endpoints","title":"Endpoints","text":""},{"location":"openapi/#get-apiv1","title":"GET /api/v1","text":"<p>Api Home</p> Description <p>API root endpoint showing available endpoints</p> <p> Response 200 OK </p> application/json Schema of the response body"},{"location":"openapi/#post-apiv1data-workflow","title":"POST /api/v1/data-workflow","text":"<p>Data Workflow</p> Description <p>Handle data workflow by uploading files and assigning metadata.</p> <p>Request body</p> multipart/form-data <p><pre><code>{\n    \"dataset_id\": \"string\",\n    \"file\": \"TG9yZW0gaXBzdW0gZG9sb3Igc2l0IGFtZXQ=\",\n    \"file_name\": \"string\"\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the request body <pre><code>{\n    \"properties\": {\n        \"dataset_id\": {\n            \"title\": \"Dataset Id\",\n            \"type\": \"string\"\n        },\n        \"file\": {\n            \"format\": \"binary\",\n            \"title\": \"File\",\n            \"type\": \"string\"\n        },\n        \"file_name\": {\n            \"title\": \"File Name\",\n            \"type\": \"string\"\n        }\n    },\n    \"required\": [\n        \"file\",\n        \"file_name\",\n        \"dataset_id\"\n    ],\n    \"title\": \"Body_data_workflow_api_v1_data_workflow_post\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 200 OK </p> application/json <p><pre><code>{\n    \"code\": 0,\n    \"dataset\": {},\n    \"message\": \"string\"\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"code\": {\n            \"title\": \"Code\",\n            \"type\": \"integer\"\n        },\n        \"dataset\": {\n            \"additionalProperties\": true,\n            \"title\": \"Dataset\",\n            \"type\": \"object\"\n        },\n        \"message\": {\n            \"title\": \"Message\",\n            \"type\": \"string\"\n        }\n    },\n    \"required\": [\n        \"code\",\n        \"message\",\n        \"dataset\"\n    ],\n    \"title\": \"DatasetSuccessEnvelope\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 422 Unprocessable Content </p> application/json <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"title\": \"Detail\",\n            \"type\": \"array\"\n        }\n    },\n    \"title\": \"HTTPValidationError\",\n    \"type\": \"object\"\n}\n</code></pre>"},{"location":"openapi/#get-apiv1dataset","title":"GET /api/v1/dataset","text":"<p>Get Datasets</p> Description <p>Return all datasets, with optional filtering</p> <p>Input parameters</p> Parameter In Type Default Nullable Description <code>state</code> query None Ready No Optional dataset state to filter on. <code>type</code> query None No Optional dataset type to filter on. If omitted, only datasets in Ready state are returned. <p> Response 200 OK </p> application/json <p><pre><code>{\n    \"code\": 0,\n    \"datasets\": [\n        {}\n    ],\n    \"message\": \"string\"\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"code\": {\n            \"title\": \"Code\",\n            \"type\": \"integer\"\n        },\n        \"datasets\": {\n            \"items\": {\n                \"additionalProperties\": true,\n                \"type\": \"object\"\n            },\n            \"title\": \"Datasets\",\n            \"type\": \"array\"\n        },\n        \"message\": {\n            \"title\": \"Message\",\n            \"type\": \"string\"\n        }\n    },\n    \"required\": [\n        \"code\",\n        \"message\",\n        \"datasets\"\n    ],\n    \"title\": \"DatasetsSuccessEnvelope\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 422 Unprocessable Content </p> application/json <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"title\": \"Detail\",\n            \"type\": \"array\"\n        }\n    },\n    \"title\": \"HTTPValidationError\",\n    \"type\": \"object\"\n}\n</code></pre>"},{"location":"openapi/#put-apiv1datasetload","title":"PUT /api/v1/dataset/load","text":"<p>Load Dataset</p> Description <p>Move dataset files from scratchpad to permanent storage</p> <p>Request body</p> application/json <p><pre><code>{\n    \"directed\": true,\n    \"edges\": [\n        {\n            \"from\": null,\n            \"labels\": [\n                \"string\"\n            ],\n            \"to\": null\n        }\n    ],\n    \"multigraph\": true,\n    \"nodes\": [\n        {\n            \"@id\": null,\n            \"labels\": [\n                \"string\"\n            ],\n            \"properties\": {}\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the request body <pre><code>{\n    \"properties\": {\n        \"directed\": {\n            \"default\": true,\n            \"title\": \"Directed\",\n            \"type\": \"boolean\"\n        },\n        \"edges\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/Edge\"\n            },\n            \"title\": \"Edges\",\n            \"type\": \"array\"\n        },\n        \"multigraph\": {\n            \"default\": true,\n            \"title\": \"Multigraph\",\n            \"type\": \"boolean\"\n        },\n        \"nodes\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/Node\"\n            },\n            \"title\": \"Nodes\",\n            \"type\": \"array\"\n        }\n    },\n    \"required\": [\n        \"nodes\",\n        \"edges\"\n    ],\n    \"title\": \"APRequest\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 200 OK </p> application/json <p><pre><code>{\n    \"ap\": {},\n    \"code\": 0,\n    \"message\": \"string\"\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"ap\": {\n            \"additionalProperties\": true,\n            \"title\": \"Ap\",\n            \"type\": \"object\"\n        },\n        \"code\": {\n            \"title\": \"Code\",\n            \"type\": \"integer\"\n        },\n        \"message\": {\n            \"title\": \"Message\",\n            \"type\": \"string\"\n        }\n    },\n    \"required\": [\n        \"code\",\n        \"message\",\n        \"ap\"\n    ],\n    \"title\": \"APSuccessEnvelope\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 422 Unprocessable Content </p> application/json <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"title\": \"Detail\",\n            \"type\": \"array\"\n        }\n    },\n    \"title\": \"HTTPValidationError\",\n    \"type\": \"object\"\n}\n</code></pre>"},{"location":"openapi/#post-apiv1datasetregister","title":"POST /api/v1/dataset/register","text":"<p>Register Dataset</p> Description <p>Register a new dataset in Neo4j</p> <p>Request body</p> application/json <p><pre><code>{\n    \"directed\": true,\n    \"edges\": [\n        {\n            \"from\": null,\n            \"labels\": [\n                \"string\"\n            ],\n            \"to\": null\n        }\n    ],\n    \"multigraph\": true,\n    \"nodes\": [\n        {\n            \"@id\": null,\n            \"labels\": [\n                \"string\"\n            ],\n            \"properties\": {}\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the request body <pre><code>{\n    \"properties\": {\n        \"directed\": {\n            \"default\": true,\n            \"title\": \"Directed\",\n            \"type\": \"boolean\"\n        },\n        \"edges\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/Edge\"\n            },\n            \"title\": \"Edges\",\n            \"type\": \"array\"\n        },\n        \"multigraph\": {\n            \"default\": true,\n            \"title\": \"Multigraph\",\n            \"type\": \"boolean\"\n        },\n        \"nodes\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/Node\"\n            },\n            \"title\": \"Nodes\",\n            \"type\": \"array\"\n        }\n    },\n    \"required\": [\n        \"nodes\",\n        \"edges\"\n    ],\n    \"title\": \"APRequest\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 200 OK </p> application/json <p><pre><code>{\n    \"ap\": {},\n    \"code\": 0,\n    \"message\": \"string\"\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"ap\": {\n            \"additionalProperties\": true,\n            \"title\": \"Ap\",\n            \"type\": \"object\"\n        },\n        \"code\": {\n            \"title\": \"Code\",\n            \"type\": \"integer\"\n        },\n        \"message\": {\n            \"title\": \"Message\",\n            \"type\": \"string\"\n        }\n    },\n    \"required\": [\n        \"code\",\n        \"message\",\n        \"ap\"\n    ],\n    \"title\": \"APSuccessEnvelope\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 422 Unprocessable Content </p> application/json <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"title\": \"Detail\",\n            \"type\": \"array\"\n        }\n    },\n    \"title\": \"HTTPValidationError\",\n    \"type\": \"object\"\n}\n</code></pre>"},{"location":"openapi/#put-apiv1datasetupdate","title":"PUT /api/v1/dataset/update","text":"<p>Update Dataset</p> Description <p>Update a dataset in Neo4j</p> <p>Request body</p> application/json <p><pre><code>{\n    \"directed\": true,\n    \"edges\": [\n        {\n            \"from\": null,\n            \"labels\": [\n                \"string\"\n            ],\n            \"to\": null\n        }\n    ],\n    \"multigraph\": true,\n    \"nodes\": [\n        {\n            \"@id\": null,\n            \"labels\": [\n                \"string\"\n            ],\n            \"properties\": {}\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the request body <pre><code>{\n    \"properties\": {\n        \"directed\": {\n            \"default\": true,\n            \"title\": \"Directed\",\n            \"type\": \"boolean\"\n        },\n        \"edges\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/Edge\"\n            },\n            \"title\": \"Edges\",\n            \"type\": \"array\"\n        },\n        \"multigraph\": {\n            \"default\": true,\n            \"title\": \"Multigraph\",\n            \"type\": \"boolean\"\n        },\n        \"nodes\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/Node\"\n            },\n            \"title\": \"Nodes\",\n            \"type\": \"array\"\n        }\n    },\n    \"required\": [\n        \"nodes\",\n        \"edges\"\n    ],\n    \"title\": \"APRequest\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 200 OK </p> application/json <p><pre><code>{\n    \"ap\": {},\n    \"code\": 0,\n    \"message\": \"string\"\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"ap\": {\n            \"additionalProperties\": true,\n            \"title\": \"Ap\",\n            \"type\": \"object\"\n        },\n        \"code\": {\n            \"title\": \"Code\",\n            \"type\": \"integer\"\n        },\n        \"message\": {\n            \"title\": \"Message\",\n            \"type\": \"string\"\n        }\n    },\n    \"required\": [\n        \"code\",\n        \"message\",\n        \"ap\"\n    ],\n    \"title\": \"APSuccessEnvelope\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 422 Unprocessable Content </p> application/json <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"title\": \"Detail\",\n            \"type\": \"array\"\n        }\n    },\n    \"title\": \"HTTPValidationError\",\n    \"type\": \"object\"\n}\n</code></pre>"},{"location":"openapi/#get-apiv1datasetdataset_id","title":"GET /api/v1/dataset/{dataset_id}","text":"<p>Get Dataset</p> Description <p>Return dataset with a specific ID from Neo4j via MoMa API</p> <p>Input parameters</p> Parameter In Type Default Nullable Description <code>dataset_id</code> path string No <p> Response 200 OK </p> application/json <p><pre><code>{\n    \"code\": 0,\n    \"dataset\": {},\n    \"message\": \"string\"\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"code\": {\n            \"title\": \"Code\",\n            \"type\": \"integer\"\n        },\n        \"dataset\": {\n            \"additionalProperties\": true,\n            \"title\": \"Dataset\",\n            \"type\": \"object\"\n        },\n        \"message\": {\n            \"title\": \"Message\",\n            \"type\": \"string\"\n        }\n    },\n    \"required\": [\n        \"code\",\n        \"message\",\n        \"dataset\"\n    ],\n    \"title\": \"DatasetSuccessEnvelope\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 422 Unprocessable Content </p> application/json <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"title\": \"Detail\",\n            \"type\": \"array\"\n        }\n    },\n    \"title\": \"HTTPValidationError\",\n    \"type\": \"object\"\n}\n</code></pre>"},{"location":"openapi/#post-apiv1polyglotquery","title":"POST /api/v1/polyglot/query","text":"<p>Execute Query</p> Description <p>Execute a SQL query on a dataset based on an Analytical Pattern</p> <p>Request body</p> application/json <p><pre><code>{\n    \"directed\": true,\n    \"edges\": [\n        {\n            \"from\": null,\n            \"labels\": [\n                \"string\"\n            ],\n            \"to\": null\n        }\n    ],\n    \"multigraph\": true,\n    \"nodes\": [\n        {\n            \"@id\": null,\n            \"labels\": [\n                \"string\"\n            ],\n            \"properties\": {}\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the request body <pre><code>{\n    \"properties\": {\n        \"directed\": {\n            \"default\": true,\n            \"title\": \"Directed\",\n            \"type\": \"boolean\"\n        },\n        \"edges\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/Edge\"\n            },\n            \"title\": \"Edges\",\n            \"type\": \"array\"\n        },\n        \"multigraph\": {\n            \"default\": true,\n            \"title\": \"Multigraph\",\n            \"type\": \"boolean\"\n        },\n        \"nodes\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/Node\"\n            },\n            \"title\": \"Nodes\",\n            \"type\": \"array\"\n        }\n    },\n    \"required\": [\n        \"nodes\",\n        \"edges\"\n    ],\n    \"title\": \"APRequest\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 200 OK </p> application/json <p><pre><code>{\n    \"ap\": {},\n    \"code\": 0,\n    \"message\": \"string\"\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"ap\": {\n            \"additionalProperties\": true,\n            \"title\": \"Ap\",\n            \"type\": \"object\"\n        },\n        \"code\": {\n            \"title\": \"Code\",\n            \"type\": \"integer\"\n        },\n        \"message\": {\n            \"title\": \"Message\",\n            \"type\": \"string\"\n        }\n    },\n    \"required\": [\n        \"code\",\n        \"message\",\n        \"ap\"\n    ],\n    \"title\": \"APSuccessEnvelope\",\n    \"type\": \"object\"\n}\n</code></pre> <p> Response 422 Unprocessable Content </p> application/json <p><pre><code>{\n    \"detail\": [\n        {\n            \"loc\": [\n                null\n            ],\n            \"msg\": \"string\",\n            \"type\": \"string\"\n        }\n    ]\n}\n</code></pre> \u26a0\ufe0f This example has been generated automatically from the schema and it is not accurate. Refer to the schema for more information.</p> Schema of the response body <pre><code>{\n    \"properties\": {\n        \"detail\": {\n            \"items\": {\n                \"$ref\": \"#/components/schemas/ValidationError\"\n            },\n            \"title\": \"Detail\",\n            \"type\": \"array\"\n        }\n    },\n    \"title\": \"HTTPValidationError\",\n    \"type\": \"object\"\n}\n</code></pre>"},{"location":"openapi/#get-apiv1test-postgres-duckdb","title":"GET /api/v1/test-postgres-duckdb","text":"<p>Test Postgres Connection</p> <p> Response 200 OK </p> application/json Schema of the response body"},{"location":"openapi/#schemas","title":"Schemas","text":""},{"location":"openapi/#aprequest","title":"APRequest","text":"Name Type <code>directed</code> boolean <code>edges</code> Array&lt;Edge&gt; <code>multigraph</code> boolean <code>nodes</code> Array&lt;Node&gt;"},{"location":"openapi/#apsuccessenvelope","title":"APSuccessEnvelope","text":"Name Type <code>ap</code> <code>code</code> integer <code>message</code> string"},{"location":"openapi/#body_data_workflow_api_v1_data_workflow_post","title":"Body_data_workflow_api_v1_data_workflow_post","text":"Name Type <code>dataset_id</code> string <code>file</code> string(binary) <code>file_name</code> string"},{"location":"openapi/#datasetssuccessenvelope","title":"DatasetsSuccessEnvelope","text":"Name Type <code>code</code> integer <code>datasets</code> Array&lt;&gt; <code>message</code> string"},{"location":"openapi/#datasetstate","title":"DatasetState","text":"<p>Type: string</p>"},{"location":"openapi/#datasetsuccessenvelope","title":"DatasetSuccessEnvelope","text":"Name Type <code>code</code> integer <code>dataset</code> <code>message</code> string"},{"location":"openapi/#datasettype","title":"DatasetType","text":"<p>Type: string</p>"},{"location":"openapi/#edge","title":"Edge","text":"Name Type <code>from</code> <code>labels</code> Array&lt;string&gt; <code>to</code>"},{"location":"openapi/#httpvalidationerror","title":"HTTPValidationError","text":"Name Type <code>detail</code> Array&lt;ValidationError&gt;"},{"location":"openapi/#node","title":"Node","text":"Name Type <code>@id</code> <code>labels</code> Array&lt;string&gt; <code>properties</code>"},{"location":"openapi/#validationerror","title":"ValidationError","text":"Name Type <code>loc</code> Array&lt;&gt; <code>msg</code> string <code>type</code> string"},{"location":"qa/","title":"Quality Assurance","text":"<p>Key aspects of the Quality Assurance checklist that DataGEMS services must pass have been defined in the processes and documents governing the platform development and quality assurance. In this section we present a selected subset of these that are directly, publicly available.</p>"},{"location":"qa/#code-analysis","title":"Code Analysis","text":"<p>Static code analysis is the process of examining source code without executing it, to identify potential errors, vulnerabilities, or deviations from coding standards. It is typically performed using tools that analyze the code's structure, syntax, and logic to detect issues such as bugs, security flaws, or maintainability problems early in the development cycle. This helps improve code quality, reduce technical debt, and ensure compliance with best practices before the software is run or deployed.</p> <p>Static code analysis is a process that has been tied with the development and release lifecycle through the configured GitHub Actions workflow that performs security, quality and maintenability of the code base. The workflow is described in the relevant Automations section.</p>"},{"location":"qa/#code-metrics","title":"Code Metrics","text":"<p>Code metrics are quantitative measurements used to assess various aspects of source code quality and complexity. They help developers understand how maintainable, efficient, and error-prone a codebase might be. Common code metrics include lines of code (LOC), cyclomatic complexity, maintenability index, and coupling levels. By analyzing these metrics, teams can identify potential issues, enforce coding standards, and improve overall software quality throughout the development lifecycle.</p> <p>The service has configured an automated GitHub Actions workflow, as described in the relevant Automations section to calculate such metrics.</p>"},{"location":"qa/#vulnerability-checks","title":"Vulnerability checks","text":"<p>Vulnerability checks are processes used to identify known security weaknesses in software, libraries, or dependencies. These checks typically scan the codebase, configuration files, or external packages against databases of publicly disclosed vulnerabilities. By detecting issues such as outdated libraries, insecure functions, or misconfigurations, vulnerability checks help developers address security risks early and maintain a secure software environment.</p> <p>The service has configured an automated GitHub Actions workflow, as described in the relevant Automations section to perform such checks on the versioned artefacts.</p>"},{"location":"qa/#testing","title":"Testing","text":"<p>As the Gateway API mainly provides proxying, aggregation and transformation logic over the underpinning DataGEMS services, an API testing approach has been choosen to perform smoke testing on existing installations of the API, be it in local development environemnt or deployed instances. The testing approach allows the usage of the same testing scenarios while in development as well as in deployed installations. It reuses the internal integration mechanisms provided to facilitate development and communication by reusing Postman request collections.</p> <p>The testing collections can be found in the service code repository in the tests folder.</p> <p>The test collections can be executed locally using the Postman application, or by command line using the Newman CLI. To run the tests locally, one can use the following command using docker with a terminal inside the tests folder. It can also be run without docker after installing the newman library locally.</p> <pre><code>docker run --rm -v \"${PWD}:/etc/newman\" postman/newman:6-ubuntu run DataGEMS-GatewayApi-Tests.postman_collection.json --env-var \"baseUrl=&lt;...&gt;\" --env-var \"...\" --reporters cli\n</code></pre> <p>A test user must be used in order to login and permorm the authenticated operations.</p> <p>The testing collection can also be executed through the CI pipelines as described in the relevant Automations section.</p> <p>The output of the test run presents a summary of the requests performed and any errors that may have been observed.</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                       \u2502       executed \u2502        failed \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502            iterations \u2502              1 \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502              requests \u2502             16 \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502          test-scripts \u2502             16 \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502    prerequest-scripts \u2502              6 \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502            assertions \u2502             16 \u2502             0 \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 total run duration: 3.3s                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 total data received: 29.96kB (approx)                  \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 avg resp time:193ms [min:103ms, max:358ms, s.d.:100ms] \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"security/","title":"Security","text":"<p>Key aspects of the Security checklist and practices that DataGEMS services must pass have been defined in the processes and documents governing the platform development and quality assurance. In this section we present a selected subset of these that are directly, publicly available and affect the usage and configuration of the service.</p>"},{"location":"security/#authentication","title":"Authentication","text":"<p>All endpoints exposed by this service require authentication using Bearer tokens in the form of JWTs (JSON Web Tokens). Clients must include a valid token in the Authorization header of each HTTP request, using the following format:</p> <pre><code>Authorization: Bearer &lt;token&gt;\n</code></pre> <p>The service only accepts JWTs that are issued by a trusted identity provider, the DataGEMS AAI service. This issuer is responsible for authenticating users and issuing tokens with claims that the service can validate. One of the critical claims in the token is the aud (audience) claim. The value of this claim must include the identifier of this service, ensuring that the token was intended to be used with it.</p> <p>When a token is received, the service performs a series of validation steps before granting access to any endpoint. These steps typically include verifying the token\u2019s signature using the public keys published by the trusted issuer, checking the issuer iss claim to confirm it matches the expected DataGEMS AAI issuer, validating the audience aud claim to ensure the token was meant for this service, and checking the token expiration exp to confirm the token is still valid. Only if all these checks pass will the request be authenticated and passed for further processing.</p> <p>The location of the configuration governing the specific behavior is described in teh relevant Configuration section.</p>"},{"location":"security/#authorization","title":"Authorization","text":"<p>When an authenticated call reaches the service, the caller may be authorized to perform an action or not. This will have to be authorized based on the grants that are present as roles in the access token presented as well as the context in which they want to perform the operation.</p> <p>Within the service, all data access operations as well as individual actions pass authorization checks. The permissions that are checked along with the policies attached to each one is managed in a configuration file that the respective Configuration section describes.</p> <p>Possible authorization policies include:</p> <ul> <li>Context-less assignment: such as an administrator that can perform action X on entity Y, regardless of the kind of affiliation they have with the entity</li> <li>Context: An affiliation of the calling user with the entity over which the action is to be performed. The context policy it tied to an anchor entity that is treated as the affiliation bearer. In the context of DataGEMS, this entity is the Dataset</li> <li>Owner: Specific kind of affiliation between the calling user and the entity over which the action is to be performed, indicating ownership of the entity. An example is a User Collection that is owned by a specific user</li> <li>Claim: a policy similar to the Context-less permission assignment. Instead of checking specificaly the \"role\" claim type, this policy will check ad-hoc claims that have specific values to match the policy</li> <li>Client: a policy similar to the Context-less permission assignment. Instead of checking specificaly the \"role\" claim type, this policy will check the caller client id to have a specific value to match the policy</li> <li>Authenticated: Authenticated user, regardless of any other characteristic vcan be granted or not granted the specific permission</li> <li>Anonymous: Anonymous users be be granted or not granted the specific permission</li> </ul> <p>For context based authorization policies with a Dataset affiliation bearer, the evaluation of the kind of operations that the user can perfomr is done by interpreting the respective JWT \"datasets\" claim. The context is provided through the interpretation of the context grant model detailed in the DataGEMS AAI.</p> <p>For each of affiliation bearing datasets, the following actions (verbs) are interpreted to grant needed access: * browse - Grants permission to browse the dataset in a listing view and see dataset metadata * delete - Grants permission to delete the dataset * download - Grants permission to download the dataset * edit - Grants permission to edit dataset data and metadata * search - Grants permission to perform a search using the data and metadata of the dataset. This does not refer to listing / browsing operations but advanced search capabilities offered by DataGEMS</p>"},{"location":"security/#token-exchange","title":"Token exchange","text":"<p>In the microservice architecture of DataGEMS and given the role of the Gateway Api in the DataGEMS archtiecture, it is expected that the service will need to invoke other services, either outside or within the request flow of an external invocation. The service  may need to perform some out of band operation or a scheduled maintenance / system task. Or, within the context of an incoming communication, invoke a third service as part of fulfilling its operation. We separate these two cases to distinguish the authentication mechanisms that are used:</p> <ul> <li> <p>Service to Service with Client Credentials: The service needs to acquire an access token that it can present to the service it is invoking. It will initiate a client credential flow, presenting it's client id and secret, along with the scope of the access token which will indicate the audience / reciever of the generated credential. The genereted access token can then be used in the HTTP request as a Bearer token in the Authorization header.</p> </li> <li> <p>Service to Service with Exchanged Credentials: The service, in the context of serving a user request needs to invoke another service. It must forward the credentials it was invoked with to continue the process flow under the scope of the original caller. It will initiate a token exchange flow, presenting it's client id and secret so that the AAI service authorizes the client to exhcnage the requested token, along with the initial access token that needs to be exchanged and the desired scope of the new access token which will indicate the audience / reciever of the generated, exchanged credential. The genereted access token can then be used in the HTTP request as a Bearer token in the Authorization header.</p> </li> </ul> <p>These two flows are supported by the DataGEMS AAI service and the needed configuration is located as the respective Configuration section describes.</p>"},{"location":"security/#secrets","title":"Secrets","text":"<p>Secrets are a special kind of configuration that requires special handling. This is described in the respective Configuration section.</p>"}]}